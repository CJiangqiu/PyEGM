# PyEGM

**A Sample Growth Model Inspired by Physical Explosion Phenomena**  
**ä»¥ç‰©ç†çˆ†ç‚¸ç°è±¡ä¸ºçµæ„Ÿçš„æ ·æœ¬ç”Ÿé•¿æ¨¡å‹**

Language: [English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

<a id="english"></a>
<details open>
<summary><strong>English</strong></summary>

# PyEGM: A Sample Growth Model Inspired by Physical Explosion Phenomena

> Grow class-wise samples via an energyâ€“direction analogy and decide with trend-path voting. Designed for few-shot class-incremental and long-tailed regimes.  
> âš™ï¸ Backend switchable: `platform="auto"|"cpu"|"cuda"` (uses CUDA when available, otherwise falls back to CPU).

## ğŸ§  Model Inspiration

### Why â€œphysical explosion phenomenaâ€?
In few-shot and long-tailed settings, training data rarely covers the critical regions near decision boundaries. Pure interpolation or random augmentations often extrapolate poorly. We need a *direction-aware, magnitude-controlled, stage-wise* mechanism for **within-class growth**: push limited samples toward plausible boundaries while avoiding intrusions into rival classes. Explosion phenomena exhibit **instantaneous energy release â†’ outward expansion along directions â†’ anisotropy and shell-like structures under constraints â†’ front propagation in stages**. These traits align with our methodological goals, so we use them as a model inspiration rather than solving real dynamics equations.

### Our approach
- **Growth-style generation**: Allocate an â€œenergy budgetâ€ per class and expand samples along local principal directions. Parameters such as `total_energy`, `mass`, `explosion_time`, and `noise_*` control intensity and pacing.
- **Anisotropy and rival suppression**: Shape with local covariance (`anisotropy`) and deflect components toward rival class centers (`deflect_rival`, `deflect_strength`), echoing directional preference and shielding effects.
- **Shells and radius control**: Limit extrapolation using `shell_ratio`, `shell_jitter`, and `adaptive_radius_mode`, keeping synthetic â€œshellsâ€ close to plausible decision fronts.
- **Trend-path voting**: At inference, move step-by-step along each candidate class direction (`path_steps`, `path_step_size`), aggregate neighbors with weights (`path_k`, `path_gamma`, `step_weight_mode`), and fall back to majority neighbors when a path is unreliable.

## âš™ï¸ API Reference

### Constructor â€” key arguments
- **Presets & config**: `preset` (`auto|fscil|balanced_kshot|imbalanced_kshot|extreme_lowshot` or a `*.yaml` path)  
- **Generation (analogy)**: `num_points`, `total_energy`, `mass`, `explosion_time`, `noise_scale`, `noise_decay`, `dirichlet_alpha`, `dynamic_energy`  
- **Radius / shells**: `adaptive_radius_mode`, `fixed_radius`, `use_radius_clip`, `shell_ratio`, `shell_jitter`  
- **Geometry / rivalry**: `local_k`, `anisotropy`, `deflect_rival`, `deflect_strength`, `momentum_conserve`  
- **Trend-path**: `path_steps`, `path_step_size`, `path_k`, `path_gamma`, `step_weight_mode`, `step_gamma`  
- **Scheduling / stability**: `points_schedule`, `energy_schedule`, `num_iters`, `energy_decay`, `radius_growth`, `governor`  
- **Backend & env**: `platform` (`auto/cpu/cuda`), `torch_q_block`, `torch_db_block`, `random_state`

### Methods â€” quick list
- `fit(X, y)`: Train the base session, parse preset/config, synthesize growth samples, and build the retrieval backend.  
- `partial_fit(X, y, classes=None)`: Incremental update for few-shot or newly introduced classes.  
- `continue_fit(extra_iters=..., reseed=None)`: Add a small number of extra iterations on the current state (short resuming).  
- `predict(X)`: Trend-path-based prediction.  
- `score(X, y)`: Convenience evaluation.  
- `export_fixed_yaml(path, include_meta=True)`: Export the final effective hyperparameter snapshot.  
- `get_fitted_params()`: Return the final effective hyperparameter dictionary.  
- `save(dir_path)` / `load(dir_path)`: Checkpoint and restore the model (config, tensors/arrays, and backend index).  
- `visualize_explosion(...)`: 2-D projection visualization of growth and paths; supports static images and animations.

## ğŸ§© Features

### ğŸ¬ Visualization
- **What it shows**: real samples, synthetic growth samples, energy vectors, and trend paths; supports PCA / t-SNE / UMAP projections.  
- **Common arguments**: `projection`, `n_samples`, `path_steps`, `show_synthetic`, `show_energy_vectors`, `save_path` (file suffix decides `png/gif/mp4`).  
- **Dependencies**: `matplotlib`; for animations use `imageio`/`imageio-ffmpeg` or `moviepy`; UMAP requires `umap-learn`.  
- **Example**:
  ```python
  clf.visualize_explosion(
      projection="pca", n_samples=800, path_steps=6,
      show_synthetic=True, show_energy_vectors=True,
      save_path="explosion.png", show=False
  )
  ```

### ğŸ’¾ Checkpointing & ğŸ” Resuming
- **Save & restore**: `save(dir)` writes config and internal arrays, plus the needed index/cache; `PyEGM.load(dir)` restores a usable model for inference or further training.  
- **Short resuming**: `continue_fit(extra_iters=..., reseed=...)` adds a small number of iterations on the existing configuration and data to reduce retraining overhead.  
- **Incremental sessions**: `partial_fit(X, y, classes=None)` merges new samples and updates indexing; combine with save/load for staged training and evaluation.  
- **Backend choice**: `platform="auto"` uses GPU when CUDA is available, otherwise CPU. When restoring across environments, the backend is chosen by availability.

## ğŸš€ Minimal Example
```python
import numpy as np
from pyegm import PyEGM
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# Data
X, y = make_classification(n_samples=2000, n_features=64, n_classes=5, random_state=0)
Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=0)

# Initialize & train
clf = PyEGM(preset="auto", platform="auto", random_state=42)
clf.fit(Xtr.astype(np.float32), ytr)
print("Accuracy:", clf.score(Xte.astype(np.float32), yte))

# Save & resume
clf.export_fixed_yaml("pyegm_fixed.yaml")
clf.save("checkpoints/egm_run")

clf2 = PyEGM.load("checkpoints/egm_run")
clf2.continue_fit(extra_iters=3, reseed=123)
clf2.partial_fit(Xtr[:40].astype(np.float32), ytr[:40])
clf2.save("checkpoints/egm_run_after")

# Visualization (export a static image)
clf2.visualize_explosion(
    projection="pca", n_samples=800, path_steps=6,
    show_synthetic=True, show_energy_vectors=True,
    save_path="explosion.png", show=False
)
```
</details>

---

<a id="ä¸­æ–‡"></a>
<details>
<summary><strong>ä¸­æ–‡</strong></summary>

# PyEGMï¼šä»¥ç‰©ç†çˆ†ç‚¸ç°è±¡ä¸ºçµæ„Ÿçš„æ ·æœ¬ç”Ÿé•¿æ¨¡å‹

> é€šè¿‡â€œèƒ½é‡â€”æ–¹å‘â€çš„ç±»æ¯”åœ¨ç±»å†…è¿›è¡Œç”Ÿé•¿å¼ç”Ÿæˆï¼Œå¹¶ä»¥è¶‹åŠ¿è·¯å¾„æŠ•ç¥¨å®Œæˆåˆ¤åˆ«ï¼›é€‚ç”¨äºå°æ ·æœ¬å¢é‡ä¸ä¸å¹³è¡¡åœºæ™¯ã€‚  
> âš™ï¸ åç«¯å¯åˆ‡æ¢ï¼š`platform="auto"|"cpu"|"cuda"`ï¼ˆæ£€æµ‹åˆ° CUDA æ—¶å¯ç”¨ GPUï¼Œå¦åˆ™å›é€€ CPUï¼‰ã€‚

## ğŸ§  æ¨¡å‹çµæ„Ÿ

### ä¸ºä»€ä¹ˆé€‰æ‹©â€œç‰©ç†çˆ†ç‚¸ç°è±¡â€ä½œä¸ºçµæ„Ÿ
åœ¨å°æ ·æœ¬ä¸é•¿å°¾æ¡ä»¶ä¸‹ï¼ŒçœŸå®æ•°æ®éš¾ä»¥è¦†ç›–å†³ç­–è¾¹ç•Œé™„è¿‘çš„å…³é”®åŒºåŸŸï¼Œå•çº¯çš„æ’å€¼æˆ–éšæœºæ•°æ®å¢å¼ºå®¹æ˜“å¯¼è‡´è¾¹ç•Œå¤–æ¨å¤±çœŸã€‚æˆ‘ä»¬æœŸæœ›ä¸€ç§**é¢å‘è¾¹ç•Œæ–¹å‘ã€å¹…åº¦å¯æ§ã€é˜¶æ®µé€’è¿›**çš„ç±»å†…æ‰©å¼ æœºåˆ¶ï¼šæ—¢èƒ½å°†æœ‰é™æ ·æœ¬å‘æ½œåœ¨è¾¹ç•Œæ¨è¿›ï¼Œåˆé¿å…è¶Šç•Œåˆ°å¯¹æ‰‹ç±»åˆ«çš„åŠ¿åŸŸã€‚ç‰©ç†çˆ†ç‚¸ç°è±¡å‘ˆç°äº†**èƒ½é‡ç¬æ—¶é‡Šæ”¾ â†’ ç‰©è´¨æ²¿ç‰¹å®šæ–¹å‘å¤–æ‰© â†’ å—ç¯å¢ƒçº¦æŸè€Œäº§ç”Ÿå„å‘å¼‚æ€§ä¸å£³å±‚ç»“æ„ â†’ å‰æ²¿åˆ†é˜¶æ®µæ¨è¿›**çš„è¿‡ç¨‹ï¼Œè¿™ä¸æˆ‘ä»¬çš„æ–¹æ³•è®ºç›®æ ‡é«˜åº¦å¥‘åˆï¼Œå› æ­¤é€‰æ‹©å…¶ä½œä¸ºæ¨¡å‹çµæ„Ÿæ¥æºï¼ˆè€Œéæ±‚è§£çœŸå®åŠ¨åŠ›å­¦æ–¹ç¨‹ï¼‰ã€‚

### æˆ‘ä»¬çš„åšæ³•
- **ç”Ÿé•¿å¼ç”Ÿæˆ**ï¼šä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…â€œèƒ½é‡é¢„ç®—â€ï¼Œé©±åŠ¨æ ·æœ¬æ²¿å±€éƒ¨å‡ ä½•ä¸»è½´å‘å¤–æ‰©å¼ ï¼›`total_energyã€massã€explosion_timeã€noise_*` ç­‰å‚æ•°æ§åˆ¶ç”Ÿæˆå¼ºåº¦ä¸èŠ‚å¥ã€‚
- **å„å‘å¼‚æ€§ä¸å¯¹æ‰‹æŠ‘åˆ¶**ï¼šåŸºäºå±€éƒ¨åæ–¹å·®å¡‘å½¢ï¼ˆ`anisotropy`ï¼‰ï¼Œå¹¶å¯¹æœå‘å¯¹æ‰‹ç±»ä¸­å¿ƒçš„åˆ†é‡è¿›è¡ŒåæŠ˜/æŠ‘åˆ¶ï¼ˆ`deflect_rival, deflect_strength`ï¼‰ã€‚
- **å£³å±‚ä¸åŠå¾„æ§åˆ¶**ï¼šé€šè¿‡ `shell_ratio, shell_jitter, adaptive_radius_mode` ç­‰é™åˆ¶å¤–æ¨ç©ºé—´ï¼Œä½¿ç”Ÿæˆå£³å±‚è´´è¿‘æ½œåœ¨å†³ç­–è¾¹ç•Œã€‚
- **è¶‹åŠ¿è·¯å¾„æŠ•ç¥¨**ï¼šæ¨ç†æ—¶æ²¿å€™é€‰ç±»åˆ«æ–¹å‘å¤šæ­¥æ¨è¿›ï¼ˆ`path_steps, path_step_size`ï¼‰ï¼Œæ¯æ­¥èšåˆè¿‘é‚»å¹¶åŠ æƒï¼ˆ`path_k, path_gamma, step_weight_mode`ï¼‰ï¼›è·¯å¾„ä¸å¯é æ—¶å›é€€å¤šæ•°è¿‘é‚»è¡¨å†³ã€‚

## âš™ï¸ API è¯´æ˜

### æ„é€ å‡½æ•°å…³é”®å‚æ•°
- **é¢„è®¾ä¸é…ç½®**ï¼š`preset`ï¼ˆ`auto|fscil|balanced_kshot|imbalanced_kshot|extreme_lowshot` æˆ– `*.yaml`ï¼‰  
- **ç”Ÿæˆï¼ˆç‰©ç†ç±»æ¯”ï¼‰**ï¼š`num_points, total_energy, mass, explosion_time, noise_scale, noise_decay, dirichlet_alpha, dynamic_energy`  
- **åŠå¾„/å£³å±‚**ï¼š`adaptive_radius_mode, fixed_radius, use_radius_clip, shell_ratio, shell_jitter`  
- **å‡ ä½•/å¯¹æŠ—**ï¼š`local_k, anisotropy, deflect_rival, deflect_strength, momentum_conserve`  
- **è¶‹åŠ¿è·¯å¾„**ï¼š`path_steps, path_step_size, path_k, path_gamma, step_weight_mode, step_gamma`  
- **è°ƒåº¦/ç¨³å®š**ï¼š`points_schedule, energy_schedule, num_iters, energy_decay, radius_growth, governor`  
- **åç«¯ä¸ç¯å¢ƒ**ï¼š`platform`ï¼ˆ`auto/cpu/cuda`ï¼‰ï¼Œ`torch_q_block`, `torch_db_block`, `random_state`

### æ–¹æ³•ä¸€è§ˆ
- `fit(X, y)`ï¼šè®­ç»ƒåŸºåº§ï¼›è§£æé¢„è®¾å¹¶ç”Ÿæˆåˆæˆæ ·æœ¬ï¼Œå»ºç«‹æ£€ç´¢åç«¯ã€‚  
- `partial_fit(X, y, classes=None)`ï¼šå¢é‡è®­ç»ƒï¼ˆfew-shot / æ–°ç±»å¹¶å…¥ï¼‰ã€‚  
- `continue_fit(extra_iters=..., reseed=None)`ï¼šåœ¨å½“å‰çŠ¶æ€ä¸Šè¿½åŠ å°‘é‡è¿­ä»£ï¼ˆçŸ­ç‚¹ç»­è®­ï¼‰ã€‚  
- `predict(X)`ï¼šè¶‹åŠ¿è·¯å¾„æŠ•ç¥¨é¢„æµ‹ã€‚  
- `score(X, y)`ï¼šä¾¿æ·è¯„ä¼°ã€‚  
- `export_fixed_yaml(path, include_meta=True)`ï¼šå¯¼å‡ºæœ€ç»ˆç”Ÿæ•ˆè¶…å‚å¿«ç…§ã€‚  
- `get_fitted_params()`ï¼šè¿”å›æœ€ç»ˆç”Ÿæ•ˆè¶…å‚å­—å…¸ã€‚  
- `save(dir_path)` / `load(dir_path)`ï¼šä¿å­˜ä¸æ¢å¤æ¨¡å‹ï¼ˆåŒ…å«é…ç½®ã€å†…éƒ¨æ•°ç»„ä¸åç«¯ç´¢å¼•ï¼‰ã€‚  
- `visualize_explosion(...)`ï¼šäºŒç»´æŠ•å½±ä¸‹çš„ç”Ÿé•¿è¿‡ç¨‹ä¸è¶‹åŠ¿è·¯å¾„å¯è§†åŒ–ï¼Œæ”¯æŒå¯¼å‡ºé™å›¾/åŠ¨ç”»ã€‚

## ğŸ§© åŠŸèƒ½ä»‹ç»

### ğŸ¬ å¯è§†åŒ–
- **å±•ç¤ºå†…å®¹**ï¼šçœŸå®æ ·æœ¬ã€åˆæˆæ ·æœ¬ã€èƒ½é‡å‘é‡ã€è¶‹åŠ¿è·¯å¾„ï¼›æ”¯æŒ PCA / t-SNE / UMAP æŠ•å½±ã€‚  
- **å¸¸ç”¨å‚æ•°**ï¼š`projection`ã€`n_samples`ã€`path_steps`ã€`show_synthetic`ã€`show_energy_vectors`ã€`save_path`ï¼ˆæŒ‰åç¼€å¯¼å‡º `png/gif/mp4`ï¼‰ã€‚  
- **ä¾èµ–**ï¼š`matplotlib`ï¼›åŠ¨ç”»å¯¼å‡ºå¯é€‰ `imageio`/`imageio-ffmpeg` æˆ– `moviepy`ï¼›UMAP éœ€ `umap-learn`ã€‚  
- **ç¤ºä¾‹**ï¼š
  ```python
  clf.visualize_explosion(
      projection="pca", n_samples=800, path_steps=6,
      show_synthetic=True, show_energy_vectors=True,
      save_path="explosion.png", show=False
  )
  ```

### ğŸ’¾ ä¿å­˜ä¸ ğŸ” ç»­è®­
- **ä¿å­˜ä¸æ¢å¤**ï¼š`save(dir)` å†™å‡ºé…ç½®ä¸å†…éƒ¨æ•°ç»„ï¼Œå¹¶ä¿å­˜æ‰€éœ€ç´¢å¼•/ç¼“å­˜ï¼›`PyEGM.load(dir)` å¯åœ¨ç›®æ ‡ç¯å¢ƒä¸­æ¢å¤å¹¶ç›´æ¥æ¨ç†æˆ–ç»§ç»­è®­ç»ƒã€‚  
- **çŸ­ç‚¹ç»­è®­**ï¼š`continue_fit(extra_iters=..., reseed=...)` åœ¨æ—¢æœ‰é…ç½®ä¸æ•°æ®ä¸Šè¿½åŠ å°‘é‡è¿­ä»£ï¼Œä»¥é™ä½å†æ¬¡è®­ç»ƒå¼€é”€ã€‚  
- **å¢é‡ä¼šè¯**ï¼š`partial_fit(X, y, classes=None)` å¹¶å…¥æ–°å¢æ ·æœ¬å¹¶æ›´æ–°ç´¢å¼•ï¼›å¯ä¸ä¿å­˜/åŠ è½½ç»“åˆï¼Œç”¨äºåˆ†é˜¶æ®µè®­ç»ƒä¸è¯„ä¼°ã€‚  
- **åç«¯é€‰æ‹©**ï¼š`platform="auto"` åœ¨æ£€æµ‹åˆ° CUDA æ—¶ä½¿ç”¨ GPUï¼Œå¦åˆ™å›é€€ CPUï¼›è·¨ç¯å¢ƒæ¢å¤æ—¶æŒ‰å¯ç”¨æ€§è‡ªåŠ¨é€‰æ‹©ã€‚

## ğŸš€ æœ€å°ä½¿ç”¨ç¤ºä¾‹
```python
import numpy as np
from pyegm import PyEGM
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# æ•°æ®
X, y = make_classification(n_samples=2000, n_features=64, n_classes=5, random_state=0)
Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=0)

# åˆå§‹åŒ–ä¸è®­ç»ƒ
clf = PyEGM(preset="auto", platform="auto", random_state=42)
clf.fit(Xtr.astype(np.float32), ytr)
print("Accuracy:", clf.score(Xte.astype(np.float32), yte))

# ä¿å­˜ä¸ç»­è®­
clf.export_fixed_yaml("pyegm_fixed.yaml")
clf.save("checkpoints/egm_run")

clf2 = PyEGM.load("checkpoints/egm_run")
clf2.continue_fit(extra_iters=3, reseed=123)
clf2.partial_fit(Xtr[:40].astype(np.float32), ytr[:40])
clf2.save("checkpoints/egm_run_after")

# å¯è§†åŒ–ï¼ˆå¯¼å‡ºé™å›¾ï¼‰
clf2.visualize_explosion(
    projection="pca", n_samples=800, path_steps=6,
    show_synthetic=True, show_energy_vectors=True,
    save_path="explosion.png", show=False
)
```
</details>
